{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qg7KL0aWQwJC"
      },
      "source": [
        "# Classificazione di immagini con Convolutional Neural Network (CNN)\n",
        "\n",
        "In questa lezione, impariamo a risolvere un problema di classificazione tramite un approcchio di **Deep Learning** basato su una *Convolutional Neural Network* (CNN)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZssyrYnDRGmR"
      },
      "source": [
        "### Librerie\n",
        "Importiamo subito le librerie che utilizzeremo nella nostra soluzione.\n",
        "\n",
        "In particolare, la libreria `tensorflow` (con `keras`) è quella che ci permette di addestrare, testare e in generale gestire l'utilizzo delle reti neurali.\n",
        "\n",
        "**NB** Un MLP può essere implementato sia in Tensorflow e Keras, che in Scikit-Learn (scorsa lezione)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcH4Xacbg7bF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Model\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLXpysTPRVJ0"
      },
      "source": [
        "### Dati\n",
        "\n",
        "\n",
        "1.   Carica il file `.zip` contenente il dataset *Euclid_dataset_DL.zip* dataset (versione per il Deep Learning!) → questo lo useremo per il **training** e **validation**\n",
        "2.   Carica il file `.zip` contenente il dataset *Euclid_dataset.zip* dataset (\"standard\" version) → questo lo useremo per il **testing**\n",
        "3.   Estrai i dati con i comandi seguenti:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "z6gGq9EshL37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkdir:  cannot create extraction directory: /content\n",
            "           Permission denied\n"
          ]
        }
      ],
      "source": [
        "!unzip -q Euclid_dataset_DL.zip -d /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WXbaGuqmzC53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkdir:  cannot create extraction directory: /content\n",
            "           Permission denied\n"
          ]
        }
      ],
      "source": [
        "!unzip -q Euclid_dataset.zip -d /content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhllMIO4Rb3Z"
      },
      "source": [
        "### Caricamento dei dati\n",
        "\n",
        "La libreria `keras` ci mette a disposizione un comodo metodo per importare senza fatica i nostri dati.\n",
        "\n",
        "In questo caso, mettiamo **80% dei dati in training** e il rimanente **20% nel set di validazione**.\n",
        "\n",
        "**Tools**:\n",
        "   * `image_dataset_from_directory()`: crea un dataset utilizzando le immagini presenti nella cartella indicata, assegnando come etichette il nome delle cartelle presenti."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4b3sZ1ASan6"
      },
      "source": [
        "**Training** dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "goHMzLR-hBPs"
      },
      "outputs": [],
      "source": [
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    directory='Euclid_dataset_DL',\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    class_names=['triangle', 'rectangle', 'square', 'rhombus'],\n",
        "    color_mode='rgb',\n",
        "    batch_size=32,\n",
        "    image_size=(224, 224),\n",
        "    shuffle=True,\n",
        "    seed=1821,\n",
        "    validation_split=0.2,\n",
        "    subset='training',\n",
        "    interpolation='bilinear',\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xzZ26miSd_x"
      },
      "source": [
        "**Validation** dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bo-hHneVhDbK"
      },
      "outputs": [],
      "source": [
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    directory='Euclid_dataset_DL',\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    class_names=['triangle', 'rectangle', 'square', 'rhombus'],\n",
        "    color_mode='rgb',\n",
        "    batch_size=32,\n",
        "    image_size=(224, 224),\n",
        "    shuffle=True,\n",
        "    seed=1821,\n",
        "    validation_split=0.2,\n",
        "    subset='validation',\n",
        "    interpolation='bilinear',\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSL3__y_UciS"
      },
      "source": [
        "**Testing** set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3DaOGRCUfky"
      },
      "outputs": [],
      "source": [
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    directory='Euclid_dataset',\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    class_names=['triangle', 'rectangle', 'square', 'rhombus'],\n",
        "    color_mode='rgb',\n",
        "    batch_size=32,\n",
        "    image_size=(224, 224),\n",
        "    shuffle=True,\n",
        "    seed=1821,\n",
        "    validation_split=0,\n",
        "    interpolation='bilinear',\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDJaJ9lSSqtp"
      },
      "source": [
        "### Architettura della Rete Neurale (CNN)\n",
        "E' tempo di definire quale modello di *Convolutional Neural Network* (CNN) andremo ad utilizzare.\n",
        "\n",
        "Abbiamo due possibili scelte:\n",
        "\n",
        "1.   Definire la **nostra architettura**.\n",
        "2.   Usare una delle architetture proposte in letteratura.\n",
        "\n",
        "Nella nostra esercitazione, utilizziamo `MobileNet`. Utilizziamo questa rete  **pre-trained** tramite il dataset `Imagenet` dataset (i pesi della rete sono scaricati dal server remoto).\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ImPF3vGHhm58"
      },
      "outputs": [],
      "source": [
        "# Our model\n",
        "model = tf.keras.applications.MobileNet(\n",
        "    input_shape=None,\n",
        "    alpha=1.0,\n",
        "    depth_multiplier=1,\n",
        "    dropout=0.001,\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation=\"softmax\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyTIVjtv1f3P"
      },
      "source": [
        "**Problema**: come puoi vedere, il modello pre-trained ha 1000 classi in totale, i.e. il layer finale ha 1000 neuroni, mentre il nostro problema di classificazione ha solo 4 classi.\n",
        "\n",
        "E' necessario quindi adattare l'architettura. Possiamo rimuovere l'ultimo layer e rimpiazzarlo con uno con solo 4 neuroni definito da noi.\n",
        "\n",
        "**Tools**:\n",
        "\n",
        "*   [**Sequential model**](https://keras.io/guides/sequential_model/) in TensorFlow\n",
        "  *   Possiamo definire una rete come sequenza di layer (`output = Layer()(input)`)\n",
        "  *   I layer del modello sono accessibili con l'attributo `layers`\n",
        "  *   Ogni layer ha un attributo `input` e `output`. Questi attributi possono essere utilzzati per una varietà di operazioni, tra cui modificare velocemente l'architettura di un modello."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-D9sdfL-1THp"
      },
      "outputs": [],
      "source": [
        "# Create a layer where input is the output of the second last layer\n",
        "output = Dense(4, activation='softmax', name='predictions')(model.layers[-2].output)\n",
        "\n",
        "# Then create the corresponding model\n",
        "model = Model(model.input, output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ub70_6dc-ORF"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaOFM9KxbTop"
      },
      "source": [
        "### Parametri di training\n",
        "Qui sono definiti:\n",
        "\n",
        "*   Numero di **epoche**\n",
        "*   Il salvataggio del modello\n",
        "*   **Optimizer**\n",
        "*   **Funzione obiettivo**\n",
        "\n",
        "Possiamo definire anche le **callbacks**: una callback è un metodo che esegue una o più operazioni a un dato punto del training (*e.g.* all'inizio o alla fine di un'epoca, prima o dopo di un batch singolo, etc).\n",
        "\n",
        "E' necessario **compilare** il modello prima della fase di training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hD_8QfGEhvfL"
      },
      "outputs": [],
      "source": [
        "epochs = 5\n",
        "\n",
        "callbacks = [\n",
        "    # to save the model after every epoch\n",
        "    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\"),\n",
        "    # logging\n",
        "    tf.keras.callbacks.TensorBoard(log_dir=\"logs\", write_graph=True, write_images=False, update_freq=\"epoch\",)\n",
        "]\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.SGD(1e-3),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BargpIWIbsft"
      },
      "source": [
        "### Training\n",
        "Ora possiamo lanciare il nostro training: per fortuna tutta la complessità è gestita dalle librerie!\n",
        "\n",
        "Se il training è (troppo) lento, ricorda di abilitare il supporto GPU: clicca su **Runtime → Change Runtime type → GPU** (dal menù a tendina)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bt6J16Xbhzir"
      },
      "outputs": [],
      "source": [
        "model.fit(\n",
        "    train_ds, epochs=epochs, callbacks=callbacks, validation_data=val_ds,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ub_8-nvC8Ymd"
      },
      "source": [
        "### Test del modello"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGuWlkzX8gZ1"
      },
      "source": [
        "Anche in questo caso possiamo utilizzare un metodo delle librerie.\n",
        "\n",
        "E' importare specificare quale modello (ovvero quali pesi) utilizzare, visto che abbiamo i pesi della rete per ogni epoca."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Deh6quvPXPPy"
      },
      "outputs": [],
      "source": [
        "model_trained = keras.models.load_model('/content/save_at_4.h5')\n",
        "\n",
        "model_trained.evaluate(\n",
        "    x=test_ds,\n",
        "    y=None,\n",
        "    batch_size=32,\n",
        "    verbose=True,\n",
        "    sample_weight=None,\n",
        "    steps=None,\n",
        "    callbacks=None,\n",
        "    max_queue_size=10,\n",
        "    workers=1,\n",
        "    use_multiprocessing=False,\n",
        "    return_dict=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgtXy9HY5jR_"
      },
      "source": [
        "Infine, possiamo abilitare il modulo di **TensorBoard** per vedere i grafici delle nostre loss!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1aq2WVQ5hV-"
      },
      "outputs": [],
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pF--zcEKAk4_"
      },
      "source": [
        "### Architettura personalizzata\n",
        "E' anche possibile, come accennato prima, definire il proprio modello di rete convolutiva.\n",
        "\n",
        "Proviamo a implementare una nostra rete prendendo ispirazione da AlexNet (https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf), uno delle prime architetture proposte in letteratura.\n",
        "\n",
        "**NB** Se definisco una mia architettura, è improbabile trovare lo stesso modello pre-addestrato.\n",
        "\n",
        "**NBB** Dopo aver definito l'architettura, è necessario compilare nuovamente il modello e modificare la dimensione delle immagini di input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlrCrJJRAPm3"
      },
      "outputs": [],
      "source": [
        "# Import necessary components to build LeNet\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Normalization\n",
        "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "\n",
        "def our_model(img_shape=(64, 64, 3), n_classes=4, weights=None):\n",
        "\n",
        "\t# Initialize model\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Normalization(axis=-1))\n",
        "\n",
        "\t# layer 1\n",
        "  model.add(Conv2D(30, (5, 5), input_shape=img_shape))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\t# layer 2\n",
        "  model.add(Conv2D(30, (5, 5)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\t# layer 3\n",
        "  model.add(Conv2D(30, (4, 4)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\t# layer 4\n",
        "  model.add(Conv2D(30, (3, 3)))\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "\t# layer 5\n",
        "  model.add(Conv2D(120, (3, 3)))\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "\t# flatten (layer 6)\n",
        "  model.add(Flatten())\n",
        "\n",
        "  # layer 7\n",
        "  model.add(Dense(120))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "\n",
        "\t# layer 8\n",
        "  model.add(Dense(84))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "\n",
        "\t# layer 9\n",
        "  model.add(Dense(n_classes))\n",
        "  model.add(Activation('softmax'))\n",
        "\n",
        "  return model\n",
        "\n",
        "model = our_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUU3gQhy66d5"
      },
      "source": [
        "### Conclusioni\n",
        "In questa esercitazione abbiamo addestrato un modello di rete neurale!\n",
        "\n",
        "Il modello ha imparato da **solo** come **estrarre informazione** (*feature*) dalle immagini e come **risolvere il problema di classificazione** (grazie alla parte finale, il *classifier*).\n",
        "\n",
        "Questo codice è solo il **punto di partenza**, il mondo del deep learning è molto vasto, con numerosi sviluppi avvenuti anche di recente (a CVPR 2024, una delle maggiori conferenze del settore, sono stati sottomessi circa 11500 articoli!).\n",
        "\n",
        "Nel nostro codice si potrebbero inserire numerose varianti:\n",
        "\n",
        "*   Definire un modello diverso\n",
        "*   Modificare l'optimizer\n",
        "*   Modificare l'ammontare dei dati di training\n",
        "*   ... (la fantasia è l'unico limite!)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
